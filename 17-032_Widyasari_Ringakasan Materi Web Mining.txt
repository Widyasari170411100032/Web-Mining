1.	CRAWING DATA
Crawling adalah proses mesin pencari untuk menemukan halaman website gambar video dokumen dan lain sebagainya yang telah di update di sebuah situs.
Untuk pencarian sebuah konten di search engine dengan keyword tertentu maka akan mencari indeks dan konten yang mana yang paling sesuai untuk user tersebut.
Ada banyak beragam pilihan tools yang dapat digunakan untuk melakukan web Crawling salah satunya disebut sebagai web robot atau web Spider dan juga proses web rolling ini tidak dapat dilakukan secara manual

cara kerja Web Crawler
1.	Web crawler akan menuju ke laman situs dan link
2.	Masukkan URL situs di Google Search Console
3.	Web Crawling akan melakukan pencatatan pada setiap link di indeks.
note : halaman/link yang bersifat privat tidak bisa diambil informasinya
4.	informasi yang sudah terumpul maka akan di simpan di dalam indeks search engine sehingga muncul di konten dengan keyword yang sama

Contoh Web Crawler
1.	Googlebot, web crawler milik Google yang paling banyak digunakan saat ini. Gogglebot akan membuat indeks yang akan bertugas untuk mengumpulkan informasi dari berbagai website.
2.	HTTrack, web crawler yang bersifat open source. ketika user sudah mendownload aplikasi ini maka user bia membuka konten situs tanpa melalui koneksi internet 
3.	Cyotek WebCopy, sama halnya seperti HTTrack yang membedakan user dapat memilih bagian mana yang ingin di download.
4.	Webhose, web crawler yang mengubah konten menjadi datafeeds


2.	TEXT PREPROCESSING
-	Case Folding
Case folding adalah salah satu bentuk text preprocessing yang paling sederhana dan efektif meskipun sering diabaikan. Tujuan dari case folding untuk mengubah semua huruf dalam dokumen menjadi huruf kecil. Hanya huruf ‘a’ sampai ‘z’ yang diterima. Karakter selain huruf dihilangkan dan dianggap delimiter. Pada tahap ini tidak menggunakan external library apapun, kita bisa memanfaatkan modul yang tersedia di python.
import re # impor modul regular expression
kalimat = "Berikut ini adalah 5 negara dengan pendidikan terbaik di dunia adalah Korea Selatan, Jepang, Singapura, Hong Kong, dan Finlandia."
hasil = re.sub(r"\d+", "", kalimat)
print(hasil)# ouput

# Berikut ini adalah negara dengan pendidikan terbaik di dunia adalah Korea Selatan, Jepang, Singapura, Hong Kong, dan Finlandia.

-	Tokenisasi
Tokenizing adalah proses pemisahan teks menjadi potongan-potongan yang disebut sebagai token untuk kemudian di analisa. Kata, angka, simbol, tanda baca dan entitas penting lainnya dapat dianggap sebagai token. Didalam NLP, token diartikan sebagai “kata” meskipun tokenize juga dapat dilakukan pada paragraf maupun kalimat.
Fungsi split()pada pyhton dapat digunakan untuk memisahkan teks. Perhatikan contoh dibawah ini :
kalimat = "rumah idaman adalah rumah yang bersih"
pisah = kalimat.split()
print(pisah)# output

# ['rumah', 'idaman', 'adalah', 'rumah', 'yang', 'bersih']

-	Stemming
Stemming adalah proses menghilangkan infleksi kata ke bentuk dasarnya, namun bentuk dasar tersebut tidak berarti sama dengan akar kata (root word). Misalnya kata “mendengarkan”, “dengarkan”, “didengarkan” akan ditransformasi menjadi kata “dengar”.
Ada banyak algoritma yang digunakan untuk stemming. Salah satu algoritma yang tertua dan paling populer adalah algoritma Porter. Algoritma ini tersedia dalam modul NLTK melalui kelasPorterStemmer().
from nltk.stem import PorterStemmer 
   
ps = PorterStemmer() 
  
kata = ["program", "programs", "programer", "programing", "programers"] 
  
for k in kata: 
         print(k, " : ", ps.stem(k))# ouput

# program  :  program
programs  :  program
programer  :  program
programing  :  program
programers  :  program

-	Filtering (Stopword Removal)
Filtering adalah tahap mengambil kata-kata penting dari hasil token dengan menggunakan algoritma stoplist (membuang kata kurang penting) atau wordlist (menyimpan kata penting).
Stopword adalah kata umum yang biasanya muncul dalam jumlah besar dan dianggap tidak memiliki makna. Contoh stopword dalam bahasa Indonesia adalah “yang”, “dan”, “di”, “dari”, dll. Makna di balik penggunaan stopword yaitu dengan menghapus kata-kata yang memiliki informasi rendah dari sebuah teks, kita dapat fokus pada kata-kata penting sebagai gantinya. Contoh penggunaan filtering dapat kita temukan pada konteks mesin pencarian. Jika permintaan pencarian anda adalah “apa itu pengertian manajemen?” tentunya anda ingin sistem pencarian fokus pada memunculkan dokumen dengan topik tentang “pengertian manajemen” di atas dokumen dengan topik “apa itu”. Hal ini dapat dilakukan dengan mencegah kata dari daftar stopword dianalisa.
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
 
kalimat = "Andi kerap melakukan transaksi rutin secara daring atau online. Menurut Andi belanja online lebih praktis & murah."
kalimat = kalimat.translate(str.maketrans('','',string.punctuation)).lower()
 
tokens = word_tokenize(kalimat)
listStopword =  set(stopwords.words('indonesian'))
 
removed = []
for t in tokens:
    if t not in listStopword:
        removed.append(t)
 
print(removed)# ouput
# ['andi', 'kerap', 'transaksi', 'rutin', 'daring', 'online', 'andi', 'belanja', 'online', 'praktis', 'murah']


3.	Modelling (Text Clustering Text / Classification)
-	Clustering Merupakan tugas deskripsi yang banyak digunakan dalam mengidentifikasi sebuah himpunan terbatas pada kategori atau cluster untuk mendeskripsikan data yang ditelaah.
Tujuan metode ini adalah mengelompokkan data yang homogen/sejenis sehingga data yang berada di cluster yang sama mempunyai banyak kesamaan dibanding dengan data yang ada di cluster yang berbeda.
Contoh : Pengelompokan dokumen berdasarkan topiknya
Clustering juga disebut sebagai segmentation. Metode ini digunakan untuk mengidentifikasi kelompok alami dari sebuah kasus yang di dasarkan pada sebuah kelompok atribut, mengelompokkan data yang memiliki kemiripan atribut.
Clustering adalah metode data mining yang Unsupervised, karena tidak ada satu atributpun yang digunakan untuk memandu proses pembelajaran, jadi seluruh atribut input diperlakukan sama. Kebanyakan Algoritma Clustering membangun sebuah model melalui serangkaian pengulangan dan berhenti ketika model tersebut telah memusat atau berkumpul (batasan dari segmentasi ini telah stabil).

-	Classification adalah metode yang paling umum pada data mining. Persoalan bisnis sperti Churn Analysis, dan Risk Management biasanya melibatkan metode Classification.Classification adalah tindakan untuk memberikan kelompok pada setiap keadaan. Setiap keadaan berisi sekelompok atribut, salah satunya adalah class attribute. Metode ini butuh untuk menemukan sebuah model yang dapat menjelaskan class attribute itu sebagai fungsi dari input attribute.
Keuntungan Model Klasifikasi
•	Predictive accuracy
•	Hit rate
•	Speed
•	Model building; predicting
•	Robustness
•	Scalability
•	Interpretability
•	Transparency, explainability













